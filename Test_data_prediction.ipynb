{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e570364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import load_img\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_number = '003'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d28164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(y, y_pred):\n",
    "    \"\"\"\n",
    "    Since the competion computes the error based on Euclidian distances, this function computes\n",
    "    the error for predicted and ground truth results.\n",
    "    \n",
    "    @param: list y. a (1, 2) list with original coordinations.\n",
    "    @param: list y_pred. a (1, 2) list containing the predicted coordinations.\n",
    "    \n",
    "    @return: float error. The Euclidian distance between these two given datapoints.\n",
    "    \"\"\"\n",
    "    error = np.sqrt(np.abs(y[0] - y_pred[0]) ** 2 + np.abs(y[1] - y_pred[1]) ** 2)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc46e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_original_coordination(predicted_coordination, original_box_coordination):\n",
    "    \"\"\"\n",
    "    Computes the coordinations of the predicted Hexbug's head's coordination in the original image\n",
    "    using the bounding box coordinations.\n",
    "    \n",
    "    @param: list predicted_coordination. a (1, 2) list with (x, y) format.\n",
    "    @param: list original_box_coordination. a (1, 2) list with (x, y) format of bounding box.\n",
    "    \n",
    "    @return: list. Coordinations of the predicted Hexbug's head's coordination in the original image\n",
    "    \"\"\"\n",
    "    return (predicted_coordination[0] + original_box_coordination[0], predicted_coordination[1] + original_box_coordination[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = tf.keras.models.load_model(\"resnet50_trained_model_data/v1.2/checkpoint_callback/\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fc1fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'Test_data/test{video_number}_prep.csv').drop(['Unnamed: 0'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_array = []\n",
    "\n",
    "# os.mkdir(f'Test_data/annotated_images/{video_number}')\n",
    "\n",
    "for idx, frame_name in enumerate(os.listdir(f'Test_data/cropped_bugs/{video_number}')):\n",
    "    img_path = f'Test_data/cropped_bugs/{video_number}/{frame_name}'\n",
    "    \n",
    "    original_image_path = f'Test_data/Frames/{video_number}/{frame_name}'\n",
    "    \n",
    "    sample_id = int(frame_name.split('.')[0][5:])\n",
    "    \n",
    "    img = load_img(img_path)\n",
    "    np_img = np.array(img)\n",
    "\n",
    "    expanded_img = np.expand_dims(np_img, 0)\n",
    "    predicted = list(map(int, reconstructed_model.predict(expanded_img)[0]))\n",
    "    \n",
    "    radius = 10\n",
    "    color = (0, 255, 0)\n",
    "    thickness = -1\n",
    "    \n",
    "    cv2.circle(np_img, predicted, radius, color, thickness)\n",
    "    cv2.imshow('sample', np_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Computes the coordination of the Hexbug's head in the original image.\n",
    "#     scaled_coordinations = compute_original_coordination(predicted, (data.iloc[sample_id].OriginalBoxCoordinationX1, data.iloc[sample_id].OriginalBoxCoordinationY1))\n",
    "    \n",
    "#     result_array.append([sample_id, 0, scaled_coordinations[0], scaled_coordinations[1]])\n",
    "    \n",
    "    # Reads and converts the original image into numpy array.\n",
    "#     original_sample_img = np.array(load_img(original_image_path))\n",
    "\n",
    "#     cv2.circle(original_sample_img, scaled_coordinations, radius, color, thickness)\n",
    "    \n",
    "#    print('------------------------------------------------------------------------')\n",
    "    \n",
    "#     if not os.path.exists('annotated_images'):\n",
    "#         os.mkdir('annotated_images')\n",
    "    \n",
    "#     cv2.imshow(f'Sample ID. {frame_name}', original_sample_img)\n",
    "    \n",
    "#     cv2.imwrite(f'Test_data/annotated_images/{video_number}/{frame_name}', original_sample_img)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d19037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import exportTool as export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb5cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [] # you can skip this step\n",
    "for val in result_array: \n",
    "    tmp = export.fromArrayToDict(val,tmp) #  fromArrayToDict(val)\n",
    "\n",
    "export.saveList(tmp, f\"Test_data/test{video_number}_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
