{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "275adc06",
   "metadata": {},
   "source": [
    "# Training Resnet50 for Head's Position Detection\n",
    "After preparing the `margined_cropped_images`, and `data.csv`, now we are able to feed them to a model to predict Hexbugs' heads' position.\n",
    "The approach that we managed to work with was using ***transfer learning*** to build a better model. For this, we used pre-trained `Resnet50` model, which is trained on `CoCo` dataset. This helps us to extract feature better. Hoever, top layers of the `resnet` model are used for classification tasks. To modify the model to suit our problem, we removed tha last `Dense` layer and added two other `Dense` layers to build a regressor with only ***two*** outputs for `(x, y)`.\n",
    "After modifying the model, we can train it over our dataset, and evaluate its performance on the validation set.\n",
    "At last, we save the model for further use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cbfa65",
   "metadata": {},
   "source": [
    "### Essential Imports\n",
    "\n",
    "* `cv2` is required to read and write images.\n",
    "* `json` is used to open `json` files.\n",
    "* `random` is used to pick random samples for model evaluation.\n",
    "* `logging` is used to ignore `warning` messages. (not mandatory)\n",
    "* `numoy` is cruicial to work with images.\n",
    "* `pandas` is used to read the `data.csv` file.\n",
    "* `tensorflow` is used to create model. it's used as background for `Keras`.\n",
    "* `sklearn` is used to split dataset to `train` and `test` sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "058346ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f247aa3",
   "metadata": {},
   "source": [
    "### Reading data from `data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f1de72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CroppedHexBugCoordinationX</th>\n",
       "      <th>CroppedHexBugCoordinationY</th>\n",
       "      <th>OriginalBoxCoordinationX1</th>\n",
       "      <th>OriginalBoxCoordinationX2</th>\n",
       "      <th>OriginalBoxCoordinationY1</th>\n",
       "      <th>OriginalBoxCoordinationY2</th>\n",
       "      <th>Path</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>197</td>\n",
       "      <td>95</td>\n",
       "      <td>923</td>\n",
       "      <td>1223</td>\n",
       "      <td>91</td>\n",
       "      <td>391</td>\n",
       "      <td>cropped_bugs/training04/frame0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>41</td>\n",
       "      <td>31</td>\n",
       "      <td>591</td>\n",
       "      <td>891</td>\n",
       "      <td>218</td>\n",
       "      <td>518</td>\n",
       "      <td>cropped_bugs/training05/frame0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>90</td>\n",
       "      <td>154</td>\n",
       "      <td>140</td>\n",
       "      <td>440</td>\n",
       "      <td>374</td>\n",
       "      <td>674</td>\n",
       "      <td>cropped_bugs/training01/frame0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>197</td>\n",
       "      <td>95</td>\n",
       "      <td>908</td>\n",
       "      <td>1208</td>\n",
       "      <td>581</td>\n",
       "      <td>881</td>\n",
       "      <td>cropped_bugs/training03/frame0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>104</td>\n",
       "      <td>175</td>\n",
       "      <td>66</td>\n",
       "      <td>366</td>\n",
       "      <td>263</td>\n",
       "      <td>563</td>\n",
       "      <td>cropped_bugs/training06/frame0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CroppedHexBugCoordinationX  CroppedHexBugCoordinationY  \\\n",
       "497                         197                          95   \n",
       "396                          41                          31   \n",
       "201                          90                         154   \n",
       "100                         197                          95   \n",
       "302                         104                         175   \n",
       "\n",
       "     OriginalBoxCoordinationX1  OriginalBoxCoordinationX2  \\\n",
       "497                        923                       1223   \n",
       "396                        591                        891   \n",
       "201                        140                        440   \n",
       "100                        908                       1208   \n",
       "302                         66                        366   \n",
       "\n",
       "     OriginalBoxCoordinationY1  OriginalBoxCoordinationY2  \\\n",
       "497                         91                        391   \n",
       "396                        218                        518   \n",
       "201                        374                        674   \n",
       "100                        581                        881   \n",
       "302                        263                        563   \n",
       "\n",
       "                                   Path  ID  \n",
       "497  cropped_bugs/training04/frame0.jpg   0  \n",
       "396  cropped_bugs/training05/frame0.jpg   0  \n",
       "201  cropped_bugs/training01/frame0.jpg   0  \n",
       "100  cropped_bugs/training03/frame0.jpg   0  \n",
       "302  cropped_bugs/training06/frame0.jpg   0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv').drop(['Unnamed: 0'], axis=1).sort_values('ID', ascending=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481aa283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(498, 300, 300, 3)\n",
      "(498, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load the images\n",
    "images = []\n",
    "y = []\n",
    "\n",
    "# Iterates over the `data.csv` file's rows to read images and annotatopns.\n",
    "for idx, row in data.iterrows():\n",
    "    img_path = f'./{row.Path}'\n",
    "    annotations = [int(row.CroppedHexBugCoordinationX), int(row.CroppedHexBugCoordinationY)]\n",
    "    # Reads the image\n",
    "    img = load_img(img_path)\n",
    "    # Converts the image to a numpy array\n",
    "    np_img = np.array(img)\n",
    "    # Adds the image to a list of images.\n",
    "    images.append(np_img)\n",
    "    # Adds the annotations to y.\n",
    "    y.append(annotations)\n",
    "    \n",
    "X = np.array(images)\n",
    "y = np.array(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65f0e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the dataset to `train` and `test` sets with the given ratio.\n",
    "# Also, shuffles the data to prevent feeding the model same data over different runs.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "495ae437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (398, 300, 300, 3)\n",
      "X test shape: (100, 300, 300, 3)\n",
      "y train shape: (398, 2)\n",
      "y test shape: (100, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'X train shape: {X_train.shape}')\n",
    "print(f'X test shape: {X_test.shape}')\n",
    "print(f'y train shape: {y_train.shape}')\n",
    "print(f'y test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "603e0fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 01:01:00.507196: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-26 01:01:00.526702: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-26 01:01:00.526829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-26 01:01:00.528408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-26 01:01:00.528507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-26 01:01:00.528572: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-26 01:01:00.893616: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-26 01:01:00.893776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-26 01:01:00.893851: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-26 01:01:00.893917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4032 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Creates a pre-trained model instance from class `ResNet50`.\n",
    "# This model doesn't include the last classification dense layer.\n",
    "# The given `input_shape` should be the same as our dataset images.\n",
    "resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=X_train[0].shape)\n",
    "\n",
    "# Iterates over each layer in the model and makes them to be trainable.\n",
    "for layer in resnet50.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Adds two dense layers for regression problem.\n",
    "# It basically uses the output of the `resnet50` model to feed the dense layers.\n",
    "x = resnet50.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# The last layer should be the layer that computes the (x, y) coordinations.\n",
    "output_layer = Dense(2, activation='linear')(x)\n",
    "\n",
    "# Create the model based on the input and output layer.\n",
    "model = Model(inputs=resnet50.input, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bfa0a5",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "For better visualization, we use [tensorboard](https://www.tensorflow.org/tensorboard/get_started). It helps us to plot the figures real-time and analyze the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ad8d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/zsh: /home/farzam/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /usr/bin/zsh)\r\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# We need datetime to name our checkpoints.\n",
    "import datetime\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Creates a callback, which then will be called by the model during training process.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6374b0c",
   "metadata": {},
   "source": [
    "### Saving the best model\n",
    "During the training process, we need to track the model's performance and make sure that at the end of the training process, we have the best model.\n",
    "To do so, we used a custom `callback` that checks if the `val_loss` has been decreased over the past epoch. In that case, it will simply save the model to the provided directory, which can be used to load and evaluate later.\n",
    "This call back is then called by the model during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a682ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies the checkpoint directory\n",
    "checkpoint_filepath = './checkpoint_callback'\n",
    "\n",
    "# Creates an instance from the ModelCheckpoint class.\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e185478e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Since we are dealing with regression problem, it's recommended to use `mse`.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Also we use `Adam` as our optimizer.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Since we are dealing with regression problem, it's recommended to use `mse`.\n",
    "# Also we use `Adam` as our optimizer.\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1369f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints a summary of the compiled model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ae2d4",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "Now that we have everything ready, we can train the model. we pass the `validation_data` containing the `X_test` and `y_test` to the model as well.\n",
    "Also, for above mentioned checkopints, we need to call those callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "449d63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test), callbacks=[tensorboard_callback, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea0873cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the tensorboard data in jupyter notebook\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b3d7255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(y, y_pred):\n",
    "    \"\"\"\n",
    "    Since the competion computes the error based on Euclidian distances, this function computes\n",
    "    the error for predicted and ground truth results.\n",
    "    \n",
    "    @param: list y. a (1, 2) list with original coordinations.\n",
    "    @param: list y_pred. a (1, 2) list containing the predicted coordinations.\n",
    "    \n",
    "    @return: float error. The Euclidian distance between these two given datapoints.\n",
    "    \"\"\"\n",
    "    error = np.sqrt(np.abs(y[0] - y_pred[0]) ** 2 + np.abs(y[1] - y_pred[1]) ** 2)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba6964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_original_coordination(predicted_coordination, original_box_coordination):\n",
    "    \"\"\"\n",
    "    Computes the coordinations of the predicted Hexbug's head's coordination in the original image\n",
    "    using the bounding box coordinations.\n",
    "    \n",
    "    @param: list predicted_coordination. a (1, 2) list with (x, y) format.\n",
    "    @param: list original_box_coordination. a (1, 2) list with (x, y) format of bounding box.\n",
    "    \n",
    "    @return: list. Coordinations of the predicted Hexbug's head's coordination in the original image\n",
    "    \"\"\"\n",
    "    return (predicted_coordination[0] + original_box_coordination[0], predicted_coordination[1] + original_box_coordination[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a457d0",
   "metadata": {},
   "source": [
    "### Loading the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4afd61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructed_model = tf.keras.models.load_model(\"checkpoint_callback\")\n",
    "reconstructed_model = tf.keras.models.load_model(\"resnet50_trained_model_data/v1.0/checkpoint_callback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e47066",
   "metadata": {},
   "source": [
    "### Sample Evaluation\n",
    "Now that we have successfully trained the model, let's see its performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a268e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 20:06:23.367925: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 20:06:24.104231: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_predicted: [23, 161], y: [ 23 163], Error: 2.0\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "y_predicted: [44, 158], y: [ 44 157], Error: 1.0\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "y_predicted: [23, 33], y: [26 30], Error: 4.243\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "y_predicted: [36, 186], y: [ 37 185], Error: 1.414\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "y_predicted: [72, 51], y: [75 29], Error: 22.204\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "y_predicted: [235, 196], y: [236 196], Error: 1.0\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "y_predicted: [29, 54], y: [29 54], Error: 0.0\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "y_predicted: [46, 26], y: [47 27], Error: 1.414\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "y_predicted: [49, 27], y: [49 28], Error: 1.0\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "y_predicted: [37, 268], y: [ 38 267], Error: 1.414\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "\n",
    "# Chooses random indices\n",
    "random_samples_indices = random.sample(range(0, len(X_test)), num_samples)\n",
    "\n",
    "# Iterates over each index and retrieves the image and annotaion\n",
    "for sample_index in random_samples_indices:\n",
    "    sample_img = X_test[sample_index]\n",
    "    \n",
    "    # Configs for drawing a circle on the image.\n",
    "    center = y_test[sample_index]\n",
    "    radius = 5\n",
    "    # Color map is BGR\n",
    "    color = (0, 255, 0)\n",
    "    color_pred = (0, 0, 255)\n",
    "    thickness = 5\n",
    "    \n",
    "    # Since we predict only one image at a time, we need to expand its dimention\n",
    "    # to fit the input layer of our model.\n",
    "    expanded_img = np.expand_dims(sample_img, axis=0)\n",
    "    \n",
    "    # Predicts the coordinations\n",
    "    predicted = list(map(int, reconstructed_model.predict(expanded_img)[0]))\n",
    "    \n",
    "    # Computes the error\n",
    "    error = round(compute_error(center, predicted), 3)\n",
    "    \n",
    "    print(f'y_predicted: {predicted}, y: {center}, Error: {error}')\n",
    "    \n",
    "    # Draws a circle centered in the correct coordination.\n",
    "    img_lv1 = cv2.circle(sample_img, center, radius, color, thickness)\n",
    "    # Draws a circle centered in the predicted coordination.\n",
    "    img_lv2 = cv2.circle(img_lv1, predicted, radius, color_pred, thickness)\n",
    "    \n",
    "    # Shows the output image.\n",
    "    cv2.imshow(f'Sample No. {sample_index}, error: {error}', img_lv2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5219f9d1",
   "metadata": {},
   "source": [
    "### Sample for coordination convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50fe6cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "Sample ID: 485\n",
      "Truth: [283, 116], Predicted: [282, 116], Error: 1.0\n",
      "------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Sample ID: 471\n",
      "Truth: [157, 57], Predicted: [152, 62], Error: 7.071\n",
      "------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Sample ID: 55\n",
      "Truth: [41, 99], Predicted: [41, 98], Error: 1.0\n",
      "------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Sample ID: 192\n",
      "Truth: [265, 180], Predicted: [262, 178], Error: 3.606\n",
      "------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Sample ID: 136\n",
      "Truth: [271, 30], Predicted: [270, 29], Error: 1.414\n",
      "------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Sample ID: 194\n",
      "Truth: [261, 183], Predicted: [258, 181], Error: 3.606\n",
      "------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Sample ID: 225\n",
      "Truth: [37, 213], Predicted: [36, 212], Error: 1.414\n",
      "------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Sample ID: 193\n",
      "Truth: [215, 20], Predicted: [215, 19], Error: 1.0\n",
      "------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Sample ID: 182\n",
      "Truth: [122, 133], Predicted: [122, 134], Error: 1.0\n",
      "------------------------------------------------------------------------\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Sample ID: 236\n",
      "Truth: [231, 190], Predicted: [229, 188], Error: 2.828\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "\n",
    "random_samples_indices = random.sample(range(0, len(data)), num_samples)\n",
    "\n",
    "for sample_id in random_samples_indices:\n",
    "    sample_img_path = data.iloc[sample_id].Path\n",
    "\n",
    "    # Constructs the path to the original frame\n",
    "    original_image_path = f\"Videos/{sample_img_path.split('/')[1]}/{sample_img_path.split('/')[2]}\"\n",
    "\n",
    "    sample_img = np.array(load_img(sample_img_path))\n",
    "\n",
    "    expanded_img = np.expand_dims(sample_img, axis=0)\n",
    "\n",
    "    predicted = list(map(int, reconstructed_model.predict(expanded_img)[0]))\n",
    "\n",
    "    radius = 10\n",
    "    color = (0, 255, 0)\n",
    "    thickness = -1\n",
    "\n",
    "    # Computes the coordination of the Hexbug's head in the original image.\n",
    "    scaled_coordinations = compute_original_coordination(predicted, (data.iloc[sample_id].OriginalBoxCoordinationX1, data.iloc[sample_id].OriginalBoxCoordinationY1))\n",
    "\n",
    "    # Reads and converts the original image into numpy array.\n",
    "    original_sample_img = np.array(load_img(original_image_path))\n",
    "\n",
    "    annotated_img = cv2.circle(sample_img, predicted, radius, color, thickness)\n",
    "\n",
    "    cv2.circle(original_sample_img, scaled_coordinations, radius, color, thickness)\n",
    "    \n",
    "    center = [data.iloc[sample_id].CroppedHexBugCoordinationX, data.iloc[sample_id].CroppedHexBugCoordinationY]\n",
    "    \n",
    "    error = round(compute_error(center, predicted), 3)\n",
    "    \n",
    "    file_name = f'Sample ID: {sample_id}\\nTruth: {center}, Predicted: {predicted}, Error: {error}'\n",
    "    \n",
    "    print(file_name)\n",
    "    print('------------------------------------------------------------------------')\n",
    "    \n",
    "    if not os.path.exists('annotated_images'):\n",
    "        os.mkdir('annotated_images')\n",
    "    \n",
    "    cv2.imshow(f'Sample ID. {sample_id}', original_sample_img)\n",
    "    cv2.imwrite(f'annotated_images/{file_name}.jpg', original_sample_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe4851c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
